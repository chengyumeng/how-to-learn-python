# 手把手教你写 Python：豆瓣小组在聊啥

从前，我有一个老婆，她想知道豆瓣下厨房小组里都在聊什么，所以让我写了一段代码来解决这个问题。

哎，你是不是也有类似需求呢？你应该从这里从那里听说过“爬虫”这个概念，但是实事求是的讲，我们怎么用爬虫解决这个问题呢？

我们打开这个小组，看一下我们大概要哪些信息？大概是所有帖子的：
- 标题
- 作者
- 内容

还有下面每一条的评论和作者。

从我们人类访问这些信息的角度，大概是要先访问帖子列表页，包括翻页，
然后对帖子进行点击，在帖子内部去获取详情和评论，对于一些热帖，还要涉及到评论的翻页操作。

所谓爬虫，就是用 Python 或者其他语言，去写代码，模拟人类的这样的操作，并把信息储存下来，仅此而已。

今天我们就尝试下做这件事。

我们依赖的工具很简单，包括：
- Chrome 
- Postman （https://www.postman.com/downloads/ ）

postman 可能很多人之前没用过，可以在这个地址上下载，这个地址会在这个视频的评论区，我也会放在 github 上。

然后我们需要用到两个包
- requests
- BeautifulSoup4

requests 是进行网络请求的，这个很好理解，想想你的电脑没网的时候是没法访问豆瓣的，这个包时做网络请求的。

BeautifulSoup4 做的是另外一个事情，我们知道网页返回的信息，我们管它叫 dom，它是一个树状结构。

BeautifulSoup4 就是做这个解析的，并从里面拿到我们需要的信息。

然后我们来一步步探索下怎么写出这个爬虫。

分析页面，右键，inspect，或者在你的浏览器可能叫检查元素。然后我们发现在第一个链接中，能找到页面上的数据内容，并且它的格式是 text/html。

这种是最古老最简单的页面组织方式。

我们邮件 copy as cURL。

然后打开 postman import，send，就能拿到这个请求，preview 一下可以看到除了美观度，和浏览器上看到的内容大致相同、

在 Postman 上，可以帮助我们生成代码，我们选择用 Python requests 生成的格式。复制到 jupyterlab 里，先不执行，备用。

然后我们在 postman 里找一下我们需要的字段。

我们发现一个规律，所有的帖子都在 class 为 "title" 的 td 标签下的 a 标签里。

而对我们有用的信息，包括下面 a 标签的 href 和 a 标签的 title。

因此我们可以用 BeautifulSoup4 取出这些信息。

我们知道豆瓣上一个小组下的帖子是超过一个页面的，然后我们凭借经验看一下，发现它 URL 里有个 start 的参数。每页是 25 条数据，我们递增处理即可。

因此我们考虑写一个函数去获取全部的帖子，为了让它更通用，我们给它传 2 个参数，一个是小组 ID，另外一个是页码。

尝试一下，这个代码运行正常。

再一个我们进一步可能是想分析页面详情的内容，这个方法是相似的。我们打开一个页面快速走下流程。


以上就是今天想要给大家分享的内容。回顾一下我们写爬虫用到的工具：
Chrome 的控制台
Postman
还有Python的开源库，requests 和 BeautifulSoup4。

想想它们都是干啥的？

今天讲的核心代码同样都会被放到 github 上供大家自取，下次我们讲解下如何把这些爬取的数据存储到我们自己的电脑上进行读写，感谢大家的时间，我们下周见。


